{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"alfa-challenge.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonstantinLihota/Resume/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22alfa_challenge_ipynb_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from typing import List\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from sklearn.metrics import classification_report\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Sampler\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "kH90Rn9ert4_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWYSeRdhnsob",
        "outputId": "59a1a8d2-99b4-4efb-f574-f95b35d8e6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\"\n",
        "#device = 'cpu'\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')\n",
        "#from reco_utils.recommender.sar.sar_singlenode import SARSingleNode\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = pd.read_csv('/content/gdrive/MyDrive/data/df_train.csv', sep = ';')\n",
        "df_test = pd.read_csv('/content/gdrive/MyDrive/data/df_train.csv', sep = ';')"
      ],
      "metadata": {
        "id": "2voWF8CApBYW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Data'] = df_train.Data.apply(lambda s: list(map(int, s.split(','))))\n",
        "df_train['Target'] = df_train.Target.apply(lambda s: list(map(int, s.split(','))))\n",
        "df_test['Data'] = df_test.Data.apply(lambda s: list(map(int, s.split(','))))"
      ],
      "metadata": {
        "id": "Io9vKczrpBcO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean([len(set(i)) for i in df_train['Target']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcSfuhzmnVxS",
        "outputId": "f217acdd-6ada-42c4-bfc2-2f6546b367d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.511446040096687"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_len = [len(i) for i in df_train['Data']]\n",
        "plt.hist(transaction_len,bins = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "F9McgejbpBfg",
        "outputId": "157abd41-0f5b-4f18-f870-9faa40a4b742"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.537e+03, 1.817e+03, 4.450e+02, 1.310e+02, 3.100e+01, 1.900e+01,\n",
              "        7.000e+00, 7.000e+00, 4.000e+00, 1.000e+00, 2.000e+00, 3.000e+00,\n",
              "        2.000e+00, 0.000e+00, 2.000e+00, 6.000e+00, 0.000e+00, 0.000e+00,\n",
              "        1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
              "        2.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 3.000e+00, 1.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 1.000e+00,\n",
              "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 1.000e+00]),\n",
              " array([   40.  ,   461.22,   882.44,  1303.66,  1724.88,  2146.1 ,\n",
              "         2567.32,  2988.54,  3409.76,  3830.98,  4252.2 ,  4673.42,\n",
              "         5094.64,  5515.86,  5937.08,  6358.3 ,  6779.52,  7200.74,\n",
              "         7621.96,  8043.18,  8464.4 ,  8885.62,  9306.84,  9728.06,\n",
              "        10149.28, 10570.5 , 10991.72, 11412.94, 11834.16, 12255.38,\n",
              "        12676.6 , 13097.82, 13519.04, 13940.26, 14361.48, 14782.7 ,\n",
              "        15203.92, 15625.14, 16046.36, 16467.58, 16888.8 , 17310.02,\n",
              "        17731.24, 18152.46, 18573.68, 18994.9 , 19416.12, 19837.34,\n",
              "        20258.56, 20679.78, 21101.  ]),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(transaction_len).describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4ppJx95n5fGg",
        "outputId": "eaca6e32-e016-4936-86c0-2201e06a24e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count   7033.000000\n",
              "mean     473.322906\n",
              "std      811.665063\n",
              "min       40.000000\n",
              "25%      180.000000\n",
              "50%      336.000000\n",
              "75%      570.000000\n",
              "max    21101.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82d63d97-0c14-49ff-b26e-7aa64d7b8b68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>473.322906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>811.665063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>180.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>336.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>570.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>21101.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82d63d97-0c14-49ff-b26e-7aa64d7b8b68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82d63d97-0c14-49ff-b26e-7aa64d7b8b68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82d63d97-0c14-49ff-b26e-7aa64d7b8b68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_codes = df_train['Data'].explode().value_counts()\n",
        "top  = set(top_codes[top_codes>3000].index)\n"
      ],
      "metadata": {
        "id": "u3UKmUdBpBmT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_set = [set(i) for i in df_train['Data']]\n",
        "\n",
        "def getDictionary(transaction_set, flag_lab = False):\n",
        "  all = set()\n",
        "  for i in transaction_set:\n",
        "    all|=i\n",
        "  all = list(all)\n",
        "  dictionary = {}\n",
        "  j = 0\n",
        "  for i in range(len(all)):\n",
        "    if flag_lab:\n",
        "      if all[i] in top:\n",
        "        dictionary.update({all[i]:j})\n",
        "        j+=1\n",
        "    else:\n",
        "        dictionary.update({all[i]:j})\n",
        "        j+=1\n",
        "\n",
        "\n",
        "  return dictionary\n",
        "  \n",
        "dictionary = getDictionary(transaction_set)\n",
        "dictionary_lab = getDictionary(transaction_set, True)"
      ],
      "metadata": {
        "id": "R2i9aPaipBjJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_lab[5912]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZOcldy65NAY",
        "outputId": "11ed1de8-7361-41aa-cbfe-9cf9907d2b4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp0YjDFIGnEl",
        "outputId": "4875ec70-5a6d-4883-f341-523d1cae778d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6011    700677\n",
              "6010    490602\n",
              "4814    473396\n",
              "5411    472408\n",
              "4829    307388\n",
              "         ...  \n",
              "9402        24\n",
              "6513        23\n",
              "5697        19\n",
              "8244        13\n",
              "7629        11\n",
              "Name: Data, Length: 184, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(top_codes).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "68b1cBOE6ohW",
        "outputId": "bfdef3fc-a695-4333-eaf1-eee0653af2d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Data\n",
              "count     184.00000\n",
              "mean    18091.73913\n",
              "std     83063.01458\n",
              "min        11.00000\n",
              "25%       108.75000\n",
              "50%       564.00000\n",
              "75%      3767.50000\n",
              "max    700677.00000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98382b1f-25f1-4515-aa78-b406fce07ce5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>184.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>18091.73913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>83063.01458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>108.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>564.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3767.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>700677.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98382b1f-25f1-4515-aa78-b406fce07ce5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98382b1f-25f1-4515-aa78-b406fce07ce5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98382b1f-25f1-4515-aa78-b406fce07ce5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df_train['Data']\n",
        "label = df_train['Target']"
      ],
      "metadata": {
        "id": "a7GCu2J2pBpI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSgGh0t3gPa",
        "outputId": "a5c9b228-5f52-4a8f-921f-d8fbce4ee987"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4112,\n",
              " 4812,\n",
              " 4814,\n",
              " 4816,\n",
              " 4829,\n",
              " 4900,\n",
              " 5200,\n",
              " 5211,\n",
              " 5261,\n",
              " 5311,\n",
              " 5331,\n",
              " 5399,\n",
              " 5411,\n",
              " 5499,\n",
              " 5533,\n",
              " 5541,\n",
              " 5621,\n",
              " 5641,\n",
              " 5651,\n",
              " 5661,\n",
              " 5691,\n",
              " 5699,\n",
              " 5712,\n",
              " 5722,\n",
              " 5732,\n",
              " 5735,\n",
              " 5812,\n",
              " 5813,\n",
              " 5814,\n",
              " 5912,\n",
              " 5921,\n",
              " 5941,\n",
              " 5942,\n",
              " 5945,\n",
              " 5964,\n",
              " 5977,\n",
              " 5983,\n",
              " 5995,\n",
              " 5999,\n",
              " 6010,\n",
              " 6011,\n",
              " 6012,\n",
              " 6051,\n",
              " 7311,\n",
              " 7399,\n",
              " 7832,\n",
              " 7994,\n",
              " 7995,\n",
              " 8099,\n",
              " 8999}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter([11,11,11,21,21,31]).most_common(1)[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTBf53ZZy2Zp",
        "outputId": "07790cf6-ec7d-4db8-861b-bc69cd4102ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "for i in range(len(label)):\n",
        "  for j in range(10):\n",
        "    if label[i][j] not in top:\n",
        "      label[i][j] = 8999 #Counter(label[i]).most_common(1)[0][0]\n",
        "\n",
        "len(set(np.array([np.array(i) for i in label]).reshape(-1,)))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_2O_70L3Z-J",
        "outputId": "9c4de2bd-3b41-49a5-e6b7-facf19a98bf6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [' '.join([str(dictionary[i]) for i in transact]) for transact in df_train['Data']]\n",
        "vectorizer = CountVectorizer()\n",
        "tr = TfidfTransformer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "tr.fit(X)\n",
        "tfdf_date = tr.transform(X).toarray()"
      ],
      "metadata": {
        "id": "5mkxBYFvDPtd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1,2,3,4]\n",
        "l[-2:]"
      ],
      "metadata": {
        "id": "twncGu9jgd4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6413fb1-0fea-4020-e7bb-67ed6b6abe0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_codes = df_train['Data'].explode().value_counts().head(10)\n",
        "def get_top_codes(transactions, top_n=10, drop_from=5):\n",
        "    transactions_stats = sorted(\n",
        "        Counter(transactions).items(), \n",
        "        key=lambda x: x[1], \n",
        "        reverse=True\n",
        "    )[:top_n]\n",
        "    \n",
        "\n",
        "    top_codes = [mcc_code for (mcc_code, count) in transactions_stats if count >= drop_from]\n",
        "    top_codes += list(top10_codes.index)\n",
        "\n",
        "    return top_codes[:10]\n",
        "\n",
        "\n",
        "context = df_train['Data'].apply(get_top_codes)"
      ],
      "metadata": {
        "id": "yva3Gi7ey6s5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(label):\n",
        "\n",
        "    label = label[0]\n",
        "    for j in range(10):\n",
        "      if label[j] not in top:\n",
        "        label[j] = 8999 #Counter(label[i]).most_common(1)[0][0]\n",
        "    return [label ]\n",
        "\n",
        "class SegDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data,cont,labels = None, batch_size = 522):\n",
        "    self.df = []\n",
        "    self.label = []\n",
        "    self.context = []\n",
        "    for ind in range(len(data)):\n",
        "      #i = 0\n",
        "      histr = data[ind]\n",
        "      #while len(histr) > i + batch_size+10:\n",
        "      #self.df.append([histr[i:i+batch_size-10]])\n",
        "      #self.label.append( transform([histr[i + batch_size - 10:i + batch_size]]))\n",
        "      #self.context.append(cont[ind])\n",
        "      #i+=batch_size \n",
        "\n",
        "      if len(histr) < batch_size:\n",
        "\n",
        "          histr = histr*(batch_size//len(histr)+1)\n",
        "          self.df.append(histr[-batch_size:])\n",
        "          self.label.append(labels[ind])\n",
        "          self.context.append(cont[ind])\n",
        "      elif labels is not None:\n",
        "          self.df.append(histr[-batch_size:])\n",
        "          self.label.append(labels[ind])\n",
        "          self.context.append(cont[ind])\n",
        "      \n",
        "      \n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "\n",
        "     if len(self.df[index])==1:\n",
        "       self.df[index] = self.df[index][0]\n",
        "       self.label[index] = self.label[index][0]\n",
        "\n",
        "     return {\"data\": torch.tensor([dictionary[i] for i in self.df[index]]) , \"label\": torch.tensor([dictionary_lab[i] for i in self.label[index]]), 'context': torch.tensor([dictionary[i] for i in self.context[index]])}\n",
        "\n",
        "  def __len__(self):\n",
        "     return len(self.label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = SegDataset(train, context ,label)\n",
        "train_dataset,valid_dataset  = random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8 )])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aIiUBvSC6lqY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZtqTVS6S-SV5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegTestDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data,context, batch_size = 522):\n",
        "    self.df = [] \n",
        "    self.context = []\n",
        "    for ind in range(len(data)):\n",
        "      i = 0\n",
        "      histr = data[ind]\n",
        "      self.context.append(context[ind])\n",
        "      \n",
        "      if len(histr) < batch_size:\n",
        "\n",
        "          histr = histr*(batch_size//len(histr)+1)\n",
        "          self.df.append(histr[10:batch_size])\n",
        "          #print(len(histr[10:batch_size]))\n",
        "\n",
        "      else:\n",
        "          self.df.append(histr[:batch_size-10])\n",
        "          #print(len(histr[10:batch_size]))\n",
        " \n",
        "      \n",
        "      \n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "     #print(self.label[index])\n",
        "     if len(self.df[index])==1:\n",
        "       self.df[index] = self.df[index][0]\n",
        "     #print(torch.tensor([dictionary[i] for i in self.df[index]]),  self.label[index] )\n",
        "\n",
        "     return {\"data\": torch.tensor([dictionary[i] for i in self.df[index]]), 'context': torch.tensor([dictionary[i] for i in self.context[index]])}\n",
        "\n",
        "  def __len__(self):\n",
        "     return len(self.df)\n",
        "\n",
        "context = df_test['Data'].apply(get_top_codes)\n",
        "dataset = SegTestDataset(df_test['Data'],context)\n",
        "test_dataset = torch.utils.data.Subset(dataset, range(len(dataset)))\n",
        "test_dataset[7]"
      ],
      "metadata": {
        "id": "oO-CuBtOJiCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb4bc6d-6fe3-48bd-93ff-dc56c4bae900"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': tensor([149, 147,  96, 149, 147,  77,  97,  82, 148, 161]),\n",
              " 'data': tensor([149, 149, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149,  96,\n",
              "         147, 149, 149, 149, 149, 149, 149, 149, 149, 149,  93, 149, 149, 149,\n",
              "          96, 149, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149, 149,\n",
              "         149, 149,  97, 149,  96, 149, 149, 147, 106, 149, 149, 149,  96, 149,\n",
              "         149, 147, 149,  97, 149, 149, 149,  96,  97,  97, 149,  64, 149, 149,\n",
              "         149,  93, 149,  96, 149, 149, 149, 149, 147, 149, 149, 149, 149, 149,\n",
              "         149, 149, 147, 147, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149,\n",
              "         147,  96, 149, 147, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149,\n",
              "         149, 147, 149, 149, 149, 149, 149, 149, 149,  96, 147, 149, 149, 149,\n",
              "         149, 149, 149, 149, 149, 149,  93, 149, 149, 149,  96, 149, 149, 149,\n",
              "         149, 147, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,  97, 149,\n",
              "          96, 149, 149, 147, 106, 149, 149, 149,  96, 149, 149, 147, 149,  97,\n",
              "         149, 149, 149,  96,  97,  97, 149,  64, 149, 149, 149,  93, 149,  96,\n",
              "         149, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149, 147, 147,\n",
              "         149, 149, 147, 149, 149, 149, 149, 149, 149, 149, 147,  96, 149, 147,\n",
              "         149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149, 147, 149, 149,\n",
              "         149, 149, 149, 149, 149,  96, 147, 149, 149, 149, 149, 149, 149, 149,\n",
              "         149, 149,  93, 149, 149, 149,  96, 149, 149, 149, 149, 147, 149, 149,\n",
              "         149, 149, 149, 149, 149, 149, 149, 149,  97, 149,  96, 149, 149, 147,\n",
              "         106, 149, 149, 149,  96, 149, 149, 147, 149,  97, 149, 149, 149,  96,\n",
              "          97,  97, 149,  64, 149, 149, 149,  93, 149,  96, 149, 149, 149, 149,\n",
              "         147, 149, 149, 149, 149, 149, 149, 149, 147, 147, 149, 149, 147, 149,\n",
              "         149, 149, 149, 149, 149, 149, 147,  96, 149, 147, 149, 149, 149, 147,\n",
              "         149, 149, 149, 149, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149,\n",
              "         149,  96, 147, 149, 149, 149, 149, 149, 149, 149, 149, 149,  93, 149,\n",
              "         149, 149,  96, 149, 149, 149, 149, 147, 149, 149, 149, 149, 149, 149,\n",
              "         149, 149, 149, 149,  97, 149,  96, 149, 149, 147, 106, 149, 149, 149,\n",
              "          96, 149, 149, 147, 149,  97, 149, 149, 149,  96,  97,  97, 149,  64,\n",
              "         149, 149, 149,  93, 149,  96, 149, 149, 149, 149, 147, 149, 149, 149,\n",
              "         149, 149, 149, 149, 147, 147, 149, 149, 147, 149, 149, 149, 149, 149,\n",
              "         149, 149, 147,  96, 149, 147, 149, 149, 149, 147, 149, 149, 149, 149,\n",
              "         149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149,  96, 147, 149,\n",
              "         149, 149, 149, 149, 149, 149, 149, 149,  93, 149, 149, 149,  96, 149,\n",
              "         149, 149, 149, 147, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
              "          97, 149,  96, 149, 149, 147, 106, 149, 149, 149,  96, 149, 149, 147,\n",
              "         149,  97, 149, 149, 149,  96,  97,  97, 149,  64, 149, 149, 149,  93,\n",
              "         149,  96, 149, 149, 149, 149, 147, 149])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class ReviewsSampler(Sampler):\n",
        "    def __init__(self, subset, batch_size=32):\n",
        "        self.batch_size = batch_size\n",
        "        self.subset = subset\n",
        "\n",
        "        self.indices = subset.indices\n",
        "\n",
        "        self.data = np.array(subset.dataset.df)[self.indices]\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        batch_idx = []\n",
        "\n",
        "        for index in np.argsort(list(map(len, self.data))):\n",
        "            batch_idx.append(index)\n",
        "            if len(batch_idx) == self.batch_size:\n",
        "                yield batch_idx\n",
        "                batch_idx = []\n",
        "\n",
        "        if len(batch_idx) > 0:\n",
        "            yield batch_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h7r0Fx1j0R-f"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_sampler=ReviewsSampler(train_dataset,batch_size=64))\n",
        "valid_loader = DataLoader(valid_dataset, batch_sampler=ReviewsSampler(valid_dataset, batch_size=64))\n"
      ],
      "metadata": {
        "id": "U5bVEN5KpBr_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset,  batch_sampler=ReviewsSampler(test_dataset,batch_size=64))"
      ],
      "metadata": {
        "id": "v0s1vweXyDsV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in test_loader:\n",
        "  #print(i['data'][0])\n",
        "  break\n",
        "for i in train_loader:\n",
        "  print(i['data'].shape, i['context'].shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "K7rTS7Pf6sVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d35291-0a34-4dca-d1a6-35061d4748e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 522]) torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, emb_cont_dim, k,  dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) \n",
        "        #print(emb_cont_dim)\n",
        "        self.embedding_context =  nn.Linear(k, emb_cont_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, src, context):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #print(src.shape)\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #print(embedded.shape)\n",
        "        emb_cont =self.relu( self.dropout(self.embedding_context (context.to(torch.float))))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\n",
        "        #print(hidden.shape,emb_cont.shape)\n",
        "        hidden = torch.concat((hidden,emb_cont.unsqueeze(0)), axis = 2)\n",
        "        #outputs = [src len, batch size, hid dim + emb_cont_dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, outputs"
      ],
      "metadata": {
        "id": "uCXl1EL--Om4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, context):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #context = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #context = [1, batch size, hid dim]\n",
        "        #print(input.shape, hidden.shape, context.shape)\n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\n",
        "            \n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\n",
        "        #print(emb_con.shape, hidden.shape)\n",
        "        output, hidden = self.rnn(emb_con, hidden)\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \n",
        "                           dim = 1)\n",
        "        \n",
        "        #output = [batch size, emb dim + hid dim * 2]\n",
        "        \n",
        "        prediction = self.fc_out(output)\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "G2juCLnaeERZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NiSCAZk7fPcx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 284\n",
        "EMB_SIZE = 256\n",
        "EMB_CONT_SIZE = 64\n",
        "HID_DIM = 128\n",
        "DROPOUT = 0.1"
      ],
      "metadata": {
        "id": "fkICHJXYy6FF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(SIZE, EMB_SIZE, HID_DIM,EMB_CONT_SIZE, 10, DROPOUT)\n",
        "decoder = Decoder(50, EMB_SIZE , HID_DIM + EMB_CONT_SIZE, DROPOUT)"
      ],
      "metadata": {
        "id": "57VNiuR4Ablx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        #assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "        #    \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, src, trg,cont, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = 10\n",
        "        trg_vocab_size = 50\n",
        "        #print(src.shape, trg.shape,cont.permute(1,0)[0].unsqueeze(0).shape)\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is the context\n",
        "        context,_ =  self.encoder(src, cont)\n",
        "        \n",
        "        #context also used as the initial hidden state of the decoder\n",
        "        hidden = context\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = torch.tensor([0]*src.shape[1]).to(device)\n",
        "\n",
        "        for t in range( trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and the context state\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            #print(input.shape, hidden.shape, context.shape, trg[0,:].shape)\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            #teacher_force = torch.random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] #if teacher_force else top1\n",
        "        #print(outputs.shape)\n",
        "        return outputs\n",
        "model = Seq2Seq(encoder, decoder, device = device)# разобраться с размерностями\n",
        "#model(l,o,c)"
      ],
      "metadata": {
        "id": "wlJDKSvtBORp"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictScoring(nn.Module):\n",
        "     def __init__(self, input_dim, encoder, dropout = 0.05, output_dim = 50, emb_conext_dim = 64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "          \n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "     def forward(self, trans, context, label=[], k =10):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "\n",
        "        preds = None\n",
        "        for step in range(k):\n",
        "          \n",
        "          pred, _ = self.encoder(trans, context)\n",
        "          #print(pred.shape,context.shape, trans.shape)\n",
        "\n",
        "          pred =  self.relu(self.dropout(self.fc(pred)))\n",
        "\n",
        "          if preds is None:\n",
        "            preds = pred\n",
        "          else:\n",
        "            #print(preds.shape,torch.unsqueeze(pred,0).shape)\n",
        "            preds = torch.concat((preds,pred))\n",
        "          #print(trans, label)\n",
        "          if len(label)>0:\n",
        "            #print(1)\n",
        "            trans = torch.concat((trans[1:], label[step].unsqueeze(0)))\n",
        "          else:\n",
        "            #print((trans[1:].shape, torch.argmax(pred, axis =2).shape))\n",
        "            trans = torch.concat((trans[1:], torch.argmax(pred, axis =2)))\n",
        "            #print(trans.shape,torch.argmax(pred, axis =2).shape, trans[1:].shape)\n",
        "\n",
        "        return preds\n"
      ],
      "metadata": {
        "id": "__sWqcWs_fwg"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = PredictScoring(HID_DIM +  EMB_CONT_SIZE ,encoder)\n"
      ],
      "metadata": {
        "id": "ak3Ev2prz87X"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "#h = model(l.to(device), c, o.to(device))"
      ],
      "metadata": {
        "id": "Z9C7T1EpeW5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ed4b3a-96ce-4d89-d049-8948330c5824"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(284, 256)\n",
              "    (embedding_context): Linear(in_features=10, out_features=64, bias=True)\n",
              "    (rnn): GRU(256, 128)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(50, 256)\n",
              "    (rnn): GRU(448, 192)\n",
              "    (fc_out): Linear(in_features=640, out_features=50, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apk(actual, predicted, k=10):\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i, p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "def mapk(actual, predicted, k=10):\n",
        "\n",
        "    return np.mean([apk(a, p, k) for a, p in zip(np.array(actual).reshape(-1,k), np.array(predicted).reshape(-1,k))])"
      ],
      "metadata": {
        "id": "qBw2ZcbR5P1l"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "clip = 1\n",
        "\n",
        "def fit_model(model,train_loader,valid_loader,optim,criterion, epochs = 30, clip =1, save_name = 'model'):\n",
        "\n",
        "  losses = {\"train_losses\": [], \"valid_losses\": []}\n",
        "  train_history=[]\n",
        "  valid_history  = []\n",
        "  best_valid_loss = float('inf')\n",
        "  model.to(device)\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    print(f\"Start eposh #{epoch}\")\n",
        "    epoch_loss =0 \n",
        "    history = []\n",
        "    i=0\n",
        "    model.train()\n",
        "    train_loss =0\n",
        "    bath_size =0\n",
        "    \n",
        "    for train_batch in train_loader:\n",
        "      \n",
        "      labels = train_batch['label'].to(device)\n",
        "      input = train_batch['data'].permute(1,0).to(device)\n",
        "      context = train_batch['context'].to(device)\n",
        "      #return  input,labels.permute(1,0),context\n",
        "      output= model(input,labels.permute(1,0),context).permute(1,2,0)\n",
        "      \n",
        "      optim.zero_grad()\n",
        "      \n",
        "      target = np.array([])\n",
        "\n",
        "      loss = criterion(output, labels) \n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optim.step()\n",
        "      bath_size+=1\n",
        "      train_loss += loss.item()\n",
        "        \n",
        "      history.append(loss.cpu().data.numpy())\n",
        "      i+=1\n",
        "      if (i+1)%3==0:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "            clear_output(True)\n",
        "            ax[0].plot(history, label='train loss')\n",
        "            ax[0].set_xlabel('Batch')\n",
        "            ax[0].set_title('Train loss')\n",
        "            if len(train_history)>0 :\n",
        "                ax[1].plot(train_history, label='general train history')\n",
        "                ax[1].set_xlabel('Epoch')\n",
        "            if len(valid_history)>0:\n",
        "                ax[1].plot(valid_history, label='general valid history')\n",
        "                print(len(gold_labels_all), len(predict_labels_all))\n",
        "                #print(classification_report(gold_labels_all, predict_labels_all))\n",
        "                print(predict_labels_all[:10], gold_labels_all[:10], predict_labels)\n",
        "\n",
        "                print(mapk(gold_labels_all, predict_labels_all))\n",
        "                plt.legend()\n",
        "            \n",
        "            plt.show()\n",
        "  \n",
        "    train_history.append(train_loss/bath_size)\n",
        "\n",
        "    model.eval()\n",
        "    bath_size =0 \n",
        "    val_loss=0 \n",
        "    predict_labels_all, gold_labels_all = np.array([]), np.array([])\n",
        "\n",
        "    for valid_batch in valid_loader:\n",
        "\n",
        "      labels = valid_batch['label'].to(device)\n",
        "      input = valid_batch['data'].permute(1,0).to(device)\n",
        "      context = valid_batch['context'].to(device)\n",
        "      #return  input,labels.permute(1,0),context\n",
        "      output= model(input,labels.permute(1,0),context).permute(1,2,0)\n",
        "      labels = labels\n",
        "      target = np.array([])\n",
        "\n",
        "      loss = criterion(output, labels)\n",
        "      bath_size+=1\n",
        "      val_loss += loss.item()\n",
        "      predict_labels = torch.argmax(output, axis =1)\n",
        "      \n",
        "      gold_labels = labels\n",
        "      predict_labels_all = np.append(predict_labels_all,predict_labels.cpu())\n",
        "      gold_labels_all = np.append(gold_labels_all,gold_labels.cpu())\n",
        "      #predict_labels_all.append(predict_labels.cpu().permute(1,0))\n",
        "      #gold_labels_all.append(gold_labels.cpu().permute(1,0))\n",
        "      #return gold_labels_all,predict_labels_all\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(model.state_dict(),f'/content/gdrive/MyDrive/Тестовое/best-val-model-{save_name}.pt')\n",
        "    valid_history.append(val_loss/(bath_size))\n",
        " \n",
        "    print(f\"End eposh #{epoch}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LcJY3VreU9AQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "y = np.array([np.array(i) for i in label]).reshape(-1,)\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
        "                                                  classes = np.array(list(dictionary_lab.keys())),\n",
        "                                                  y = y)\n",
        "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "nFtHg3j9QBsA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SJuFL6vmAim8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zFCO67fPAMoR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(output, labels, criterion = nn.CrossEntropyLoss()):\n",
        "  \n",
        "\n",
        "  i=0\n",
        "  count_dev = torch.argmax(output.permute(2,1,0), axis =1)\n",
        "\n",
        "  count_dev = np.mean([min(len(set(np.array(i.cpu()))),8) for i in count_dev.permute(1,0)])\n",
        "  \n",
        "  loss = criterion(output, labels)\n",
        "  for w in range(len(output.permute(2,1,0))):\n",
        "    w_ind = torch.argmax(output.permute(2,1,0)[w], axis =0)\n",
        "        \n",
        "    for tr in labels.permute(1,0):\n",
        "      l =+ (tr==w_ind).to(int)\n",
        "    l = l.sum()/len(l)\n",
        "\n",
        "    loss = loss - 0.1*criterion(output[w].permute(1,0), labels[w])*l\n",
        "  return loss/count_dev\n"
      ],
      "metadata": {
        "id": "PYxiPR5ZN4Bm"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criterion = nn.CrossEntropyLoss(weight = class_weights, reduction = 'mean')\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-5 )\n",
        "l, o,c = fit_model(model,train_loader,valid_loader,optim,loss , epochs = 100, clip =1, save_name = 'model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vxe38LL-1bLu",
        "outputId": "827c9750-49ee-4a97-b9ee-2dac406736a9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14070 14070\n",
            "[41. 41. 41. 23. 23. 41. 23. 23. 23. 23.] [30. 30. 23. 41. 43. 23. 41. 23. 41. 43.] tensor([[20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [28, 43, 43, 28, 28, 28, 28, 28, 28, 28],\n",
            "        [43, 43, 28, 28, 28, 43, 43, 28, 28, 28],\n",
            "        [42, 42, 42, 42, 40, 40, 42, 42, 43, 43],\n",
            "        [28, 28, 28, 41, 41, 41, 23, 28, 23, 28],\n",
            "        [28, 28, 43, 43, 27, 28, 43, 27, 28, 27],\n",
            "        [28, 28, 28, 28, 28, 28, 28, 28, 28, 28],\n",
            "        [41, 20, 41, 44, 44, 20, 44, 20, 20, 30],\n",
            "        [43, 43, 43, 43, 43, 23, 43, 43, 43, 43],\n",
            "        [20, 20, 20, 28, 17, 20, 20, 28, 20, 20],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 20, 43, 43],\n",
            "        [28, 28, 28, 28, 28, 28, 28, 28, 28, 28],\n",
            "        [17, 17, 17, 17, 17, 23, 17, 17, 17, 17],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [20,  9,  9,  9, 23, 23, 20,  9, 28, 28],\n",
            "        [42, 42, 43, 43, 43, 43, 42, 43, 43, 43],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [23, 20, 23, 20, 20, 40, 40, 40, 29, 20],\n",
            "        [20, 40, 43, 43, 28, 20, 28, 28, 43, 28],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [20, 23, 23, 23, 20, 20, 20, 20, 20, 20],\n",
            "        [20, 15, 15, 15, 15, 15, 15, 15, 15, 20],\n",
            "        [43, 43, 23, 23, 20, 23, 20, 23, 23, 43],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [43, 43, 43, 43, 28, 43, 43, 43, 43, 43],\n",
            "        [28, 28, 28, 28, 28, 28, 20, 28, 28, 28],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [43, 43, 28, 43, 43, 43, 43, 43, 43, 28],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [43, 42, 20, 43, 28, 28, 28, 42, 42, 28],\n",
            "        [20, 42, 20, 42, 42, 42, 42, 42, 20, 20],\n",
            "        [43, 43, 41, 41, 41, 41, 41, 30, 41, 43],\n",
            "        [28, 28, 28, 42, 28, 28, 42, 28, 28, 42],\n",
            "        [28, 28, 28, 43, 28, 28, 28, 28, 28, 28],\n",
            "        [43, 42, 42, 42, 43, 43, 43, 20, 42, 20],\n",
            "        [43, 23, 20, 20, 20, 40, 40, 40, 40, 40],\n",
            "        [28, 28, 28, 28, 28, 28, 28, 28, 28, 28],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [28, 23, 28, 20, 28, 20, 20, 20, 20, 20],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [28, 43, 43, 43, 48, 43, 28, 48, 43, 48],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [43, 43, 43, 42, 43, 43, 43, 42, 42, 42],\n",
            "        [43, 43, 41, 43, 43, 43, 43, 41, 43, 43],\n",
            "        [42, 28, 43, 43, 20, 28, 20, 43, 20, 23],\n",
            "        [41, 23, 20, 43, 43, 23, 43, 43, 23, 23],\n",
            "        [28, 43, 28, 28, 28, 28, 43, 28, 28, 28],\n",
            "        [28, 28, 28, 28, 28, 28, 28, 28, 28, 28],\n",
            "        [28, 28, 28, 28, 28, 28, 28, 28, 20, 20],\n",
            "        [23, 23, 23, 23, 43, 30, 23, 41, 23, 23],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [28, 28, 42, 28, 28, 42, 28, 42, 28, 28],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [28, 28, 22, 22, 28, 28, 28, 28, 22, 22],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
            "        [42, 42, 42, 42, 42, 42, 42, 42, 42, 42],\n",
            "        [43, 43, 43, 43, 20, 20, 20, 20, 43, 20]], device='cuda:0')\n",
            "0.15122087972834242\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b61541b4f103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#criterion = nn.CrossEntropyLoss(weight = class_weights, reduction = 'mean')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-1267d0394e8b>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, train_loader, valid_loader, optim, criterion, epochs, clip, save_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbath_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclean_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 w, h, d = renderer.get_text_width_height_descent(\n\u001b[0;32m--> 300\u001b[0;31m                     clean_line, self._fontproperties, ismath=ismath)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/Тестовое/best-val-model-model.pt'))#проверить на тесте брать 2 по вероятности "
      ],
      "metadata": {
        "id": "wWJt6oPa1lf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Идеи\n",
        "* Выкинуть редкие классы \n",
        "* seq2seq\n",
        "* Делить не на количество встреченых а на факт\n",
        "* Взвешеное считать по каждому клиенту \n",
        "* добавить контекст\n"
      ],
      "metadata": {
        "id": "yV45ikk-cRky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CtmkNvcKcQk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumb =  pd.read_csv('/content/gdrive/MyDrive/data/submission_baseline_2.csv')\n",
        "sumb.head()"
      ],
      "metadata": {
        "id": "3ATpQF5muFPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unpack =dict()\n",
        "for i in dictionary:\n",
        "  unpack[dictionary[i]] = i\n"
      ],
      "metadata": {
        "id": "x672RnQS5rav"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary[9399]"
      ],
      "metadata": {
        "id": "xYVJagR5_0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68aab5d2-7616-4077-cacb-8caaf1015282"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "i=0\n",
        "for test_batch in test_loader:\n",
        "\n",
        "      labels = torch.tensor([]).long()\n",
        "      model.to(device)\n",
        "      input = test_batch['data'].permute(1,0).to(device)\n",
        "      context = test_batch['context'].to(device)\n",
        "      output = model(input,context).permute(1,2,0)\n",
        "      i+=1\n",
        "      print( torch.argmax(output, axis =1))\n",
        "      predict_labels = [ preds.append([unpack[int(j)] for j in i]) for i in torch.argmax(output, axis =1)]\n",
        "      if predict_labels[0] is not None:\n",
        "        #print(np.array(predict_labels).shape)\n",
        "        preds.append(predict_labels)\n"
      ],
      "metadata": {
        "id": "0tRoYyrh2o0h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "692764f9-6f12-4ebd-8cb0-739b1e2cf458"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7be61c2a13a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-20247f8d6d9c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, cont, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrg_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = np.array([len(set(i)) for i in preds])\n",
        "k[k==1]"
      ],
      "metadata": {
        "id": "yH7mCekN8TUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(preds).shape"
      ],
      "metadata": {
        "id": "NGfUiewErWC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "jciS7C9Ishfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumb['Predicted'] = preds\n",
        "sumb = sumb[['Id', 'Predicted']]\n",
        "\n",
        "sumb = sumb.Predicted.astype(str).str.replace(',', '')\n",
        "sumb.to_csv('pred.csv')\n",
        "sumb"
      ],
      "metadata": {
        "id": "RTgvl9mS8TbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NdJATc22jW9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}